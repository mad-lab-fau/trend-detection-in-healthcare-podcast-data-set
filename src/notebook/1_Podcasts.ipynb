{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a596f7",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:##fff; padding:0px 10px; border-radius:5px;\">\n",
    "    <div align=\"center\">\n",
    "        <img src=\"https://www.mad.tf.fau.de/files/2019/04/cropped-logo_mad.png\" width=400>\n",
    "        <hr>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cedf1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\">\n",
    "    <h2 style='margin:10px 5px'> \n",
    "        Content\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "- [1. Import Packages](#1)\n",
    "- [2. Download Podcast by RSS Feed Link](#2)\n",
    "    - [2.1 Download Podcast as mp3](#2.1)\n",
    "    - [2.2 Generate metadata.csv separately](#2.2)\n",
    "- [3. Moving Podcasts from External Drive to local Dir](#3)\n",
    "- [4. Create and Move the Metadata for all Podcasts](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a707e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\">\n",
    "    <h2 style='margin:10px 5px'> \n",
    "        <a name='1' style=\"color:white; text-decoration:none;\">\n",
    "            1. Import Packages\n",
    "        </a>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8069b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import feedparser\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from scripts.podcasts import get_input, validate_input, get_feed, download_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ea78c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\">\n",
    "    <h2 style='margin:10px 5px'> \n",
    "        <a name='2' style=\"color:white; text-decoration:none;\">\n",
    "            2. Download podcast by RSS Feed Link\n",
    "        </a>\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "The following code downloads all podcast episodes of a certain podcast into the local directory, which can be defined and re-set by `local_target_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfb2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSS Feed to download and local location to download files too\n",
    "# RSS_Target = <https link to the RSS feed> \"https://securityinfive.libsyn.com/rss\"\n",
    "# local_target_dir = <local directory 'C:\\foldername\\target' format> \"C:\\Dev\\PodcastArchive\"\n",
    "\n",
    "local_target_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46cc331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting feed - https://feeds.blubrry.com/feeds/beckershealthcarepodcast.xml please wait...\n",
      "Feed loaded.\n"
     ]
    }
   ],
   "source": [
    "RSS_Target = \"https://feeds.blubrry.com/feeds/beckershealthcarepodcast.xml\"\n",
    "\n",
    "RSS_Feed = get_feed(RSS_Target)\n",
    "RSS_Feed_Items = RSS_Feed[0]\n",
    "RSS_Feed_Count = RSS_Feed[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2590d1",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 Download Podcast as MP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9720a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting feed - https://thebigunlock.com/feed/podcast please wait...\n",
      "Feed loaded.\n",
      "No Download - Podcast used only until the end of 2021\n"
     ]
    }
   ],
   "source": [
    "RSS_Feed = get_feed(RSS_Target)\n",
    "RSS_Feed_Items = RSS_Feed[0]\n",
    "RSS_Feed_Count = RSS_Feed[1]\n",
    "\n",
    "\"\"\"\n",
    "    is_valid = 0 -> Download all episodes\n",
    "    is_valid > 0 -> Download that amount of episodes\n",
    "\"\"\"\n",
    "is_valid = 0\n",
    "\n",
    "if datetime.date.today().year < 2022:\n",
    "    \n",
    "    while is_valid == 0:\n",
    "        How_Many = get_input(RSS_Feed_Count)\n",
    "        is_valid = validate_input(How_Many, RSS_Feed_Count)\n",
    "    else:\n",
    "        if int(How_Many) == 0:\n",
    "            File_Count = \"All files to - \"\n",
    "        elif int(How_Many) == 1:\n",
    "            File_Count = str(How_Many) + \" file to - \"\n",
    "        else:\n",
    "            File_Count = str(How_Many) + \" files to - \"\n",
    "        print(\"Downloading \" + File_Count + local_target_dir)\n",
    "        Download_Files(local_target_dir, RSS_Feed_Items, How_Many)\n",
    "else:\n",
    "    print(\"No Download - Podcast used only until the end of 2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a03e96",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 Generate metadata.csv separately\n",
    "\n",
    "> In case metadata is missing for the episodes, it is necessary to download them manually again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac10a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSS_PODCASTS = ['15 Minutes With The Doctor', 'Beckers Healthcare Podcast',\n",
    "       'Conversations on Health Care', 'Data Book',\n",
    "       'Digital Health Today', 'Faces of Digital Health',\n",
    "       'GeekWire Health Tech', 'Harlow on Healthcare',\n",
    "       'Health Care Rounds', 'HealthChangers', 'Healthcare IT Today',\n",
    "       'Healthcare Rap', 'Healthcare Strategies',\n",
    "       'Healthcare Triage Podcast',\n",
    "       'Healthcare Weekly - At the Forefront of Healthcare Innovation',\n",
    "       'Hospitals In Focus', 'How I Transformed This', 'Medtech Talk',\n",
    "       'Outcomes Rocket', 'Perspectives on Health and Tech',\n",
    "       'PopHealth Week',\n",
    "       'Solving Healthcare with Dr. Kwadwo Kyeremanteng',\n",
    "       'Talking HealthTech', 'The #HCBiz Show!', 'The Big Unlock',\n",
    "       'The Change Healthcare Podcast', 'The Incrementalist',\n",
    "       'The Pulse by Wharton Digital Health', 'The Tate Chronicles',\n",
    "       'This Just In']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1002d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/rss.json\", 'r') as j:\n",
    "     rss_feed = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04b362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_csv = pd.DataFrame(columns={\"podcast\", \"episode\", \"published\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2502078c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsing_podcast = False\n",
    "\n",
    "if parsing_podcast:\n",
    "\n",
    "    for i in range(len(RSS_PODCASTS)):\n",
    "\n",
    "        feed_link = rss_feed[RSS_PODCASTS[i]]\n",
    "\n",
    "        # get the rss data for each podcast\n",
    "        RSS_Target = feed_link\n",
    "        RSS_Feed = get_feed(RSS_Target)\n",
    "        RSS_Feed_Items = RSS_Feed[0]\n",
    "\n",
    "        for episode in RSS_Feed_Items[\"entries\"]:\n",
    "            published = episode[\"published_parsed\"]\n",
    "            date = str(published.tm_year) + \"-\" + str(published.tm_mon) + \"-\" + str(published.tm_mday)\n",
    "            metadata_csv = metadata_csv.append({\"podcast\": RSS_PODCASTS[i], \n",
    "                                                \"episode\": episode[\"title\"], \n",
    "                                                \"published\": str(date)}, ignore_index=True)\n",
    "\n",
    "        print(f\"Successfully parsed {RSS_PODCASTS[i]} and appended {len(RSS_Feed_Items['entries'])} entries.\")\n",
    "        \n",
    "    metadata_csv.to_csv(\"new_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e0d86",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\">\n",
    "    <h2 style='margin:10px 5px'> \n",
    "        <a name='3' style=\"color:white; text-decoration:none;\">\n",
    "            3. Moving podcasts from external drive to local directory\n",
    "        </a>\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "After transcribing all podcast episodes with the APIs Vosk (and DeepSpeech) onto the external drive due to the high volume, the text files will be moved into the local directory and the output folder will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b844c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Episodes: 2011\n"
     ]
    }
   ],
   "source": [
    "podcast_path = \"/mnt/d/master-thesis-long-do/podcasts\"\n",
    "thesis_podcast_path = \"/mnt/c/Users/timlo/PycharmProjects/master-thesis-tim-loehr/podcasts\"\n",
    "\n",
    "podcast_names = os.listdir(podcast_path)\n",
    "\n",
    "for podcast in podcast_names:\n",
    "    dir_path = os.path.join(podcast_path, podcast)\n",
    "    output_path = os.path.join(dir_path, \"output\")\n",
    "    thesis_podcast = os.path.join(thesis_podcast_path, podcast)\n",
    "    \n",
    "    if os.path.isdir(thesis_podcast):\n",
    "        \n",
    "        for text in os.listdir(output_path):\n",
    "            text_path = os.path.join(output_path, text)\n",
    "            target_path = os.path.join(thesis_podcast, text)\n",
    "            shutil.copyfile(text_path, target_path)\n",
    "        \n",
    "    else:\n",
    "        os.mkdir(thesis_podcast)\n",
    "        pass\n",
    "    \n",
    "episode_count = 0\n",
    "\n",
    "for podcast in podcast_names:\n",
    "    pc_path = os.path.join(podcast_path, podcast)\n",
    "    podcasts = os.listdir(pc_path)\n",
    "    podcasts_mp3 = podcasts[podcasts[:-4] == \"'.mp3'\"]\n",
    "    episode_count += len(podcasts_mp3)\n",
    "    \n",
    "print(f\"Number Episodes: {episode_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78979ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#5d3a8e; color:white; padding:0px 10px; border-radius:5px;\">\n",
    "    <h2 style='margin:10px 5px'> \n",
    "        <a name='4' style=\"color:white; text-decoration:none;\">\n",
    "            4. Create and move the metadata for all podcasts\n",
    "        </a>\n",
    "    </h2>\n",
    "</div>\n",
    "\n",
    "The metadata for all podcasts are stored in one central `csv` file, so it is easier managable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb27bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created metadata.csv and moves to  ../../data/metadata/metadata.csv\n"
     ]
    }
   ],
   "source": [
    "metadata_path = \"../../data/metadata/metadata.csv\"\n",
    "metadata_orig_path = \"/mnt/d/master-thesis-long-do/podcasts/_metadata\"\n",
    "\n",
    "if not os.path.isfile(metadata_path):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for meta in os.listdir(metadata_orig_path):\n",
    "        path = os.path.join(metadata_orig_path, meta)\n",
    "        shutil.copyfile(path, \"../../data/metadata/outputs/\" + meta)\n",
    "        \n",
    "        podcast_df = pd.read_csv(path)\n",
    "        df = df.append(podcast_df)\n",
    "\n",
    "    df.to_csv(\"../../data/metadata/metadata.csv\", index=False)\n",
    "    print(\"Successfully created metadata.csv and moves to \", metadata_path)\n",
    "    \n",
    "else:\n",
    "    print(\"metadata.csv already exists\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
